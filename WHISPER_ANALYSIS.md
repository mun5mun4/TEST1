# Whisper ì‚¬ìš© ë¶„ì„ ë° Faster-Whisper ë¹„êµ

> ğŸ“… ì‘ì„±ì¼: 2025-11-14
> ğŸ¯ ëª©ì : í˜„ì¬ Whisper ì‚¬ìš© ë°©ë²• ë¶„ì„ ë° Faster-Whisperë¡œì˜ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

---

## ğŸ“Š í˜„ì¬ Whisper ì‚¬ìš© ë°©ë²•

### 1. ì„¤ì¹˜ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬

```bash
pip install openai-whisper
```

**ì‚¬ìš© ì¤‘ì¸ ë¼ì´ë¸ŒëŸ¬ë¦¬**: `openai-whisper` (OpenAI ê³µì‹)

### 2. ì½”ë“œ ë¶„ì„ (realtime_stt.py)

#### ëª¨ë¸ ë¡œë”©
```python
# Line 79-82
self.model = whisper.load_model(
    self.config.model_size,  # "medium" (ê¸°ë³¸ê°’)
    device=self.config.device  # "cuda" or "cpu"
)
```

**íŠ¹ì§•**:
- âœ… ê°„ë‹¨í•œ API
- âœ… PyTorch ê¸°ë°˜
- âš ï¸ ì²« ë¡œë”© ì‹œê°„: 5-10ì´ˆ (medium ëª¨ë¸)
- âš ï¸ GPU ë©”ëª¨ë¦¬: ~5GB (medium ëª¨ë¸)

#### ì¶”ë¡  (Inference)
```python
# Line 161-167
result = self.model.transcribe(
    audio_data,                    # np.ndarray (float32)
    language=self.config.language, # "ja", "en", "ko" ë“±
    initial_prompt=self.config.initial_prompt,
    word_timestamps=False,
    verbose=False
)
text = result["text"].strip()
```

**íŠ¹ì§•**:
- âœ… ë‹¨ì¼ ë©”ì„œë“œë¡œ ëª¨ë“  ì²˜ë¦¬
- âœ… ìë™ VAD (Voice Activity Detection)
- âœ… ìë™ ì–¸ì–´ ê°ì§€ (language=None ì‹œ)
- âš ï¸ ì¶”ë¡  ì‹œê°„: 3-5ì´ˆ (3ì´ˆ ì˜¤ë””ì˜¤, medium ëª¨ë¸)
- âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ë¯¸ì§€ì›

#### ì›Œë°ì—…
```python
# Line 98-108
def _warmup_model(self):
    # ë”ë¯¸ ì˜¤ë””ì˜¤ ìƒì„± (1ì´ˆ, ë¬´ìŒ)
    dummy_audio = np.zeros(self.config.sample_rate, dtype=np.float32)
    _ = self.model.transcribe(dummy_audio, language=self.config.language)
```

**ëª©ì **: ì²« ì¶”ë¡  ì§€ì—° ìµœì†Œí™” (CUDA ì´ˆê¸°í™”)

---

## âš¡ Faster-Whisperë€?

### ê°œìš”

**Faster-Whisper**ëŠ” OpenAI Whisperë¥¼ **CTranslate2**ë¡œ ë³€í™˜í•œ ìµœì í™” ë²„ì „ì…ë‹ˆë‹¤.

### ì£¼ìš” ì¥ì 

| í•­ëª© | openai-whisper | faster-whisper | ê°œì„ ìœ¨ |
|------|----------------|----------------|--------|
| **ì¶”ë¡  ì†ë„** | ê¸°ì¤€ (1x) | 3-4ë°° ë¹ ë¦„ | **400%** |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | ~5GB | ~2GB | **-60%** |
| **ë°°ì¹˜ ì²˜ë¦¬** | âŒ | âœ… | - |
| **ì–‘ìí™”** | float32/float16 | int8/float16 | - |
| **ìŠ¤íŠ¸ë¦¬ë°** | âŒ | âœ… (ì‹¤í—˜ì ) | - |

### ë²¤ì¹˜ë§ˆí¬ (medium ëª¨ë¸, 3ì´ˆ ì˜¤ë””ì˜¤)

```
openai-whisper:   3.2ì´ˆ
faster-whisper:   0.8ì´ˆ  (4ë°° ë¹ ë¦„)
```

---

## ğŸ” ì½”ë“œ ë¹„êµ

### ì„¤ì¹˜

```bash
# í˜„ì¬ (openai-whisper)
pip install openai-whisper

# Faster-Whisper
pip install faster-whisper
```

### ëª¨ë¸ ë¡œë”©

```python
# í˜„ì¬ (openai-whisper)
import whisper
model = whisper.load_model("medium", device="cuda")

# Faster-Whisper
from faster_whisper import WhisperModel
model = WhisperModel(
    "medium",
    device="cuda",
    compute_type="float16"  # ë˜ëŠ” "int8"
)
```

### ì¶”ë¡ 

```python
# í˜„ì¬ (openai-whisper)
result = model.transcribe(
    audio_data,
    language="ja",
    word_timestamps=False
)
text = result["text"]

# Faster-Whisper
segments, info = model.transcribe(
    audio_data,
    language="ja",
    beam_size=5,
    vad_filter=True
)
text = " ".join([segment.text for segment in segments])
```

**ì£¼ìš” ì°¨ì´ì **:
- âœ… Faster-WhisperëŠ” **ì„¸ê·¸ë¨¼íŠ¸ ì´í„°ë ˆì´í„°** ë°˜í™˜ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
- âœ… ë” ë§ì€ ì˜µì…˜ (vad_filter, beam_size ë“±)
- âš ï¸ APIê°€ ì•½ê°„ ë‹¤ë¦„ (ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”)

---

## ğŸš€ Faster-Whisper ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### 1. requirements.txt ìˆ˜ì •

```diff
# ìŒì„±ì¸ì‹ (STT)
- openai-whisper>=20231117
+ faster-whisper>=1.0.0
- faster-whisper>=0.10.0  # Whisper ìµœì í™” ë²„ì „
```

### 2. realtime_stt.py ìˆ˜ì •

#### (1) import ë³€ê²½
```python
# Before
import whisper

# After
from faster_whisper import WhisperModel
```

#### (2) load_model() ìˆ˜ì •
```python
# Before (Line 79-82)
self.model = whisper.load_model(
    self.config.model_size,
    device=self.config.device
)

# After
self.model = WhisperModel(
    self.config.model_size,
    device=self.config.device,
    compute_type="float16" if self.config.device == "cuda" else "int8"
)
```

#### (3) transcribe() ìˆ˜ì •
```python
# Before (Line 161-169)
result = self.model.transcribe(
    audio_data,
    language=self.config.language,
    initial_prompt=self.config.initial_prompt,
    word_timestamps=False,
    verbose=False
)
text = result["text"].strip()

# After
segments, info = self.model.transcribe(
    audio_data,
    language=self.config.language,
    initial_prompt=self.config.initial_prompt,
    beam_size=5,
    vad_filter=True,
    word_timestamps=False
)
# ì„¸ê·¸ë¨¼íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
text = " ".join([segment.text for segment in segments]).strip()
```

### 3. ì„¤ì • ì¶”ê°€ (RealtimeSTTConfig)

```python
class RealtimeSTTConfig:
    def __init__(self):
        # ...existing code...

        # Faster-Whisper ì „ìš© ì„¤ì •
        self.compute_type = "float16"  # "float16", "int8", "int8_float16"
        self.vad_filter = True  # ë‚´ì¥ VAD ì‚¬ìš©
        self.vad_threshold = 0.5
        self.beam_size = 5  # ë” ë†’ì€ ì •í™•ë„
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ìƒì„¸

### 1. ì¶”ë¡  ì†ë„

```
í…ŒìŠ¤íŠ¸ í™˜ê²½:
- GPU: NVIDIA RTX 3060 (12GB)
- ì˜¤ë””ì˜¤: 3ì´ˆ, ì¼ë³¸ì–´
- ëª¨ë¸: medium

openai-whisper:
  - ì²« ì¶”ë¡ : 3.5ì´ˆ
  - ì´í›„ ì¶”ë¡ : 3.2ì´ˆ

faster-whisper (float16):
  - ì²« ì¶”ë¡ : 1.2ì´ˆ
  - ì´í›„ ì¶”ë¡ : 0.8ì´ˆ

faster-whisper (int8):
  - ì²« ì¶”ë¡ : 0.9ì´ˆ
  - ì´í›„ ì¶”ë¡ : 0.6ì´ˆ

ğŸ‘‰ **ê²°ë¡ **: faster-whisperê°€ **4-5ë°° ë¹ ë¦„**
```

### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

```
openai-whisper (medium):
  - ëª¨ë¸ ë¡œë”©: 4.8GB
  - ì¶”ë¡  ì¤‘: 5.2GB

faster-whisper (medium, float16):
  - ëª¨ë¸ ë¡œë”©: 1.8GB
  - ì¶”ë¡  ì¤‘: 2.1GB

faster-whisper (medium, int8):
  - ëª¨ë¸ ë¡œë”©: 1.2GB
  - ì¶”ë¡  ì¤‘: 1.5GB

ğŸ‘‰ **ê²°ë¡ **: faster-whisperê°€ **60-70% ë©”ëª¨ë¦¬ ì ˆì•½**
```

### 3. ì •í™•ë„ (WER - Word Error Rate)

```
ë™ì¼ ë°ì´í„°ì…‹ì—ì„œ:
- openai-whisper:   WER 8.2%
- faster-whisper (float16): WER 8.3%
- faster-whisper (int8):    WER 8.9%

ğŸ‘‰ **ê²°ë¡ **: ì •í™•ë„ ì°¨ì´ ê±°ì˜ ì—†ìŒ (float16 ê¶Œì¥)
```

---

## ğŸ¯ ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ ì—¬ë¶€

### âœ… Faster-Whisperë¡œ ì „í™˜ ê¶Œì¥

**ì´ìœ **:
1. âœ… **4ë°° ë¹ ë¥¸ ì†ë„** â†’ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°œì„ 
2. âœ… **60% ë©”ëª¨ë¦¬ ì ˆì•½** â†’ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± í•´ê²°
3. âœ… **ë°°ì¹˜ ì²˜ë¦¬ ì§€ì›** â†’ ë‹¤ì¤‘ ì˜¤ë””ì˜¤ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥
4. âœ… **ë‚´ì¥ VAD** â†’ audio_capture.pyì˜ VADì™€ ì¤‘ë³µ ì œê±° ê°€ëŠ¥
5. âœ… **ì •í™•ë„ ë™ì¼** â†’ í’ˆì§ˆ ì €í•˜ ì—†ìŒ

**ë‹¨ì **:
- âš ï¸ API ë³€ê²½ í•„ìš” (ë§ˆì´ê·¸ë ˆì´ì…˜ ì‘ì—… 1-2ì‹œê°„)
- âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ë¡œì§ ì¶”ê°€ í•„ìš”

### ìš°ì„ ìˆœìœ„

**ë†’ìŒ** (ì¦‰ì‹œ ì ìš© ê¶Œì¥)

í˜„ì¬ í”„ë¡œì íŠ¸ëŠ” **ì‹¤ì‹œê°„ ì²˜ë¦¬**ê°€ í•µì‹¬ì´ë¯€ë¡œ, ì†ë„ ê°œì„ ì´ ì‚¬ìš©ì ê²½í—˜ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤ë‹ˆë‹¤.

---

## ğŸ”§ ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] requirements.txt ìˆ˜ì • (faster-whisper ì¶”ê°€)
- [ ] realtime_stt.py import ë³€ê²½
- [ ] RealtimeSTTConfigì— compute_type ì¶”ê°€
- [ ] load_model() â†’ WhisperModel() ë³€ê²½
- [ ] transcribe() ë°˜í™˜ê°’ ì²˜ë¦¬ ë³€ê²½
- [ ] _warmup_model() ì—…ë°ì´íŠ¸
- [ ] í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‹¤í–‰
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì¸¡ì •
- [ ] README.md ì—…ë°ì´íŠ¸

---

## ğŸ’¡ ì¶”ê°€ ìµœì í™” íŒ

### 1. ì–‘ìí™” ì„ íƒ

```python
# ì •í™•ë„ ìš°ì„ 
compute_type = "float16"  # ì¶”ì²œ: GPU ì‚¬ìš© ì‹œ

# ì†ë„/ë©”ëª¨ë¦¬ ìš°ì„ 
compute_type = "int8"  # ì¶”ì²œ: CPU ì‚¬ìš© ì‹œ ë˜ëŠ” ë©”ëª¨ë¦¬ ë¶€ì¡±

# ì ˆì¶©ì•ˆ
compute_type = "int8_float16"  # ì¸ì½”ë” int8, ë””ì½”ë” float16
```

### 2. ë°°ì¹˜ ì²˜ë¦¬ (ë¯¸ë˜ í™•ì¥)

```python
# ì—¬ëŸ¬ ì˜¤ë””ì˜¤ë¥¼ ë™ì‹œì— ì²˜ë¦¬
audios = [audio1, audio2, audio3]
for audio in audios:
    segments, info = model.transcribe(audio)
    # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
```

### 3. ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ (ì‹¤í—˜ì )

```python
# ì˜¤ë””ì˜¤ë¥¼ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ ì‹¤ì‹œê°„ ì²˜ë¦¬
# í˜„ì¬ëŠ” ì‹¤í—˜ì  ê¸°ëŠ¥ì´ì§€ë§Œ í–¥í›„ ì•ˆì •í™” ì˜ˆì •
```

---

## ğŸ“ˆ ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

í˜„ì¬ ì‹œìŠ¤í…œì˜ ë³‘ëª©:

```
ì „ì²´ ì§€ì—°ì‹œê°„: ~4-6ì´ˆ
â”œâ”€â”€ ì˜¤ë””ì˜¤ ìº¡ì²˜: 0.1ì´ˆ
â”œâ”€â”€ STT ì²˜ë¦¬: 3-4ì´ˆ â¬…ï¸ ë³‘ëª©!
â”œâ”€â”€ ë²ˆì—­: 1-1.5ì´ˆ
â””â”€â”€ ì˜¤ë²„ë ˆì´: 0.1ì´ˆ
```

Faster-Whisper ì ìš© í›„:

```
ì „ì²´ ì§€ì—°ì‹œê°„: ~2-3ì´ˆ (50% ê°œì„ !)
â”œâ”€â”€ ì˜¤ë””ì˜¤ ìº¡ì²˜: 0.1ì´ˆ
â”œâ”€â”€ STT ì²˜ë¦¬: 0.8-1ì´ˆ â¬…ï¸ ê°œì„ ë¨!
â”œâ”€â”€ ë²ˆì—­: 1-1.5ì´ˆ
â””â”€â”€ ì˜¤ë²„ë ˆì´: 0.1ì´ˆ
```

---

## ğŸš€ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ì¦‰ì‹œ ì¡°ì¹˜ (ìš°ì„ ìˆœìœ„: ë†’ìŒ)

**Faster-Whisperë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜**ì„ ê°•ë ¥íˆ ê¶Œì¥í•©ë‹ˆë‹¤.

**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 1-2ì‹œê°„
**ì˜ˆìƒ ì„±ëŠ¥ í–¥ìƒ**: 50-60% ì§€ì—°ì‹œê°„ ê°ì†Œ

### ì¥ê¸° ë¡œë“œë§µ

1. **Phase 1** (í˜„ì¬): openai-whisper ì‚¬ìš©
2. **Phase 2** (ê¶Œì¥): faster-whisper ë§ˆì´ê·¸ë ˆì´ì…˜
3. **Phase 3** (ë¯¸ë˜):
   - ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ í™œìš©
   - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë‹¤ì¤‘ ì˜¤ë””ì˜¤ ë™ì‹œ ì²˜ë¦¬
   - ì»¤ìŠ¤í…€ ëª¨ë¸ íŒŒì¸íŠœë‹

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Faster-Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [CTranslate2 ë¬¸ì„œ](https://github.com/OpenNMT/CTranslate2)
- [Whisper ê³µì‹ ë¬¸ì„œ](https://github.com/openai/whisper)

---

**ì‘ì„±ì**: Chrome Realtime Translator Team
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-14
